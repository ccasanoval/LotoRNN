{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORÁCULO\n",
    "\n",
    "http://www.lotoideas.com/primitiva-resultados-historicos-de-todos-los-sorteos/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "import time\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Muestra una grafica de la evolucion del error de training y validacion\n",
    "def grafica(hist, offset0 = 0, offset1 = None):\n",
    "    loss = hist.history['loss'][offset0:offset1]\n",
    "    val_loss = hist.history['val_loss'][offset0:offset1]\n",
    "    epochs = range(offset0 + 1, len(loss) + offset0 + 1)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imprime todo el array sin elipsis\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_time(time_ini):\n",
    "    sec = round(time.time() - time_ini)\n",
    "    min = 0\n",
    "    if(sec > 60):\n",
    "        min = sec // 60\n",
    "        sec = sec & 60\n",
    "    print(\"TIME: \", min, \"m  \", sec, \"s\")\n",
    "\n",
    "def ini_time():\n",
    "    print(\"Procesando... \", time.ctime())\n",
    "    return time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cargar datos\n",
    "datos = pd.read_csv('Primitiva_2013_2018.csv')\n",
    "\n",
    "datos = datos.drop(labels=['comp'], axis=1)\n",
    "\n",
    "print(datos.head())\n",
    "print()\n",
    "#Poner los datos mas recientes al final...\n",
    "datos = datos.reindex(index=datos.index[::-1])\n",
    "print(datos.head())\n",
    "print()\n",
    "\n",
    "max = datos.max(1).max()\n",
    "min = datos.min(1).min()\n",
    "print(\"MAX: \", max)#49\n",
    "print(\"MIN: \", min)# 1\n",
    "print(\"DIM: \", datos.shape)\n",
    "features = max - min +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convierte los numeros enteros premiados en un array binario\n",
    "def vectorize(sequences, dimension=features):\n",
    "    res = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        res[i, sequence-min] = 1\n",
    "    return res\n",
    "\n",
    "def devectorize(valor):\n",
    "    res = []\n",
    "    for i in range(len(valor)):\n",
    "        if(valor[i] > 0):\n",
    "            res.append(i+min)\n",
    "    return res\n",
    "#print(devectorize(np.array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0])), \"\\n\")\n",
    "\n",
    "numeros = datos.drop(labels=['fecha'], axis=1)\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(numeros.head())\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(np.array(numeros))\n",
    "print(\"----------------------------------------\\n\")\n",
    "num_hot = vectorize(np.array(numeros))\n",
    "print(devectorize(num_hot[0]))\n",
    "print(devectorize(num_hot[1]))\n",
    "print(devectorize(num_hot[2]))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a = np.array(numeros)\n",
    "#b = np.zeros((6, numeros.size()))\n",
    "#b[np.arange(3), a] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide los datos en secuencias que el modelo tendrá que aprender\n",
    "seq_len = 100\n",
    "secuencias = []\n",
    "print(len(num_hot), seq_len)\n",
    "for index in range(len(num_hot) - seq_len):\n",
    "    #print(index, (num_hot[index : index + seq_len]))\n",
    "    secuencias.append(num_hot[index : index + seq_len])\n",
    "secuencias = np.array(secuencias)\n",
    "###\n",
    "print(devectorize(num_hot[0]))\n",
    "print(devectorize(secuencias[0][0]))\n",
    "print()\n",
    "print(devectorize(num_hot[seq_len-1]))\n",
    "print(devectorize(secuencias[0][seq_len-1]))\n",
    "print()\n",
    "print(devectorize(num_hot[1]))\n",
    "print(devectorize(secuencias[1][0]))\n",
    "print()\n",
    "print(devectorize(num_hot[1+seq_len-1]))\n",
    "print(devectorize(secuencias[1][seq_len-1]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(devectorize(secuencias[0][0]))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide los datos en Training y Test\n",
    "print(secuencias.shape)\n",
    "row = round(0.9 * secuencias.shape[0])\n",
    "train = secuencias[:int(row), :]\n",
    "print(train.shape)\n",
    "print(devectorize(train[0][0]))\n",
    "print(devectorize(secuencias[0][0]))\n",
    "\n",
    "\n",
    "#np.random.shuffle(train)\n",
    "\n",
    "x_train = train[:, :-1]#Todos menos el ultimo valor, que es el que hay que predecir\n",
    "print(x_train.shape)\n",
    "print(x_train[0][0])\n",
    "\n",
    "y_train = train[:, -1] #El ultimo valor, que es el que interesa predecir\n",
    "print(y_train.shape)\n",
    "x_test = secuencias[int(row):, :-1]\n",
    "print(x_test.shape)\n",
    "y_test = secuencias[int(row):, -1]\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_train.shape,  seq_len)\n",
    "\n",
    "print()\n",
    "print(devectorize(num_hot[0]))\n",
    "print(devectorize(x_train[0][0]))\n",
    "print()\n",
    "print(devectorize(num_hot[seq_len-2]))\n",
    "print(devectorize(x_train[0][seq_len-2]))\n",
    "print()\n",
    "print(devectorize(num_hot[seq_len-1]))\n",
    "print(devectorize(y_train[0]))\n",
    "print()\n",
    "print(devectorize(num_hot[x_train.shape[0]+seq_len-2]))\n",
    "print(devectorize(x_test[0][seq_len-2]))\n",
    "print()\n",
    "print(devectorize(num_hot[x_train.shape[0]+seq_len-1]))\n",
    "print(devectorize(y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model1 ->\n",
    "\n",
    "4 capas LSTM, 1 densa, epoca=35, 10m4s -> 95% error \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Crea la RNN\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=True))\n",
    "    #model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=True))\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=True))\n",
    "\n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=False))\n",
    "    #model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Dense(units=features, activation='sigmoid'))\n",
    "    #model.add(layers.Dense(units=features))\n",
    "    #model.add(layers.Activation(\"linear\"))\n",
    "\n",
    "    #start = time.time()\n",
    "    #model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    #print(\"> Compilation Time : \", round(time.time() - start), \" segundos\")\n",
    "    return model\n",
    "\n",
    "##\n",
    "def build_model2():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=True))\n",
    "    \n",
    "    #model.add(layers.Embedding(features, 32))\n",
    "    model.add(layers.Bidirectional(layers.LSTM(input_shape=(None, features), units=features, return_sequences=True)))\n",
    "    model.add(layers.Dense(features, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Entrenar la RNN\n",
    "batch_size=128\n",
    "epochs = 200\n",
    "model = build_model()\n",
    "timeini = time_ini()\n",
    "hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=0)\n",
    "print_time(timeini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Val.Loss: \", hist.history['val_loss'][epochs-1])\n",
    "grafica(hist)\n",
    "grafica(hist, 40, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeini = ini_time()\n",
    "best_epoch = 20\n",
    "model2 = build_model()\n",
    "hist2 = model2.fit(x_train, y_train, batch_size=batch_size, epochs=best_epoch, validation_split=0.05, verbose=0)\n",
    "print(\"Val.Loss: \", hist.history['val_loss'][best_epoch-1])\n",
    "print_time(timeini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grafica(hist2, 10, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = model2.predict(x_test)\n",
    "print(pred.shape)\n",
    "print()\n",
    "print(pred[0])\n",
    "print()\n",
    "print(\"REAL: \", devectorize(y_test[0]))\n",
    "print()\n",
    "\n",
    "#TODO: Si el peor de los mejores esta repetido, alguno mejor podria no entrar en la lista\n",
    "def traduce(pred):\n",
    "    min_mas_alto = sorted(pred[0], key=float, reverse=True)[5]\n",
    "    numeros = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        numeros.append([])\n",
    "        for j in range(pred.shape[1]):\n",
    "            if pred[i][j] >= min_mas_alto and len(numeros[i]) < 6:\n",
    "                numeros[i].append(j)\n",
    "    return numeros\n",
    "\n",
    "numeros_ganadores = traduce(pred)\n",
    "print(\"PRED: \", numeros_ganadores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def calc_error(pred, real):\n",
    "    error = []\n",
    "    for i in range(len(pred)):\n",
    "        error.append(0)\n",
    "        for j in range(len(pred[i])):\n",
    "            if(pred[i][j] not in real[i]):\n",
    "                error[i] += math.floor(100/6)\n",
    "    return error\n",
    "\n",
    "error = calc_error(numeros_ganadores, y_test)\n",
    "print(\"ERROR: \", error)\n",
    "err = 0\n",
    "for x in error:\n",
    "    err += x\n",
    "print(\"\\nERROR: \", err/len(error), \"% ----------------------------------------\")\n",
    "\n",
    "#pred = np.reshape(pred, (pred.size,))\n",
    "\"\"\"\n",
    "error = []\n",
    "for i in range(numeros_ganadores.shape[0]):\n",
    "    error.append(0)\n",
    "    for j in range(numeros_ganadores.shape[1]):\n",
    "        if(pred[i][j] != y_test[i][j]):\n",
    "            error[i] += 1 \"\"\"\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "notas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 32))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=1):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "            \n",
    "        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookback = 1000\n",
    "step = 1\n",
    "delay = 1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = generator(\n",
    "    num_hot,\n",
    "    lookback=lookback,\n",
    "    delay=delay,\n",
    "    min_index=0,\n",
    "    max_index=2500,\n",
    "    shuffle=False,\n",
    "    step=step,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_gen = generator(\n",
    "    num_hot,\n",
    "    lookback=lookback,\n",
    "    delay=delay,\n",
    "    min_index=2501,\n",
    "    max_index=3502,\n",
    "    step=step,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_gen = generator(\n",
    "    num_hot,\n",
    "    lookback=lookback,\n",
    "    delay=delay,\n",
    "    min_index=3502,\n",
    "    max_index=None,\n",
    "    step=step,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_steps = (3500 - 3001 - lookback)\n",
    "test_steps = (len(num_hot) - 3700 - lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hist = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n",
    "#hist = model.fit_generator(train_gen, steps_per_epoch=500, epochs=20, validation_data=val_gen, validation_steps=val_steps)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
