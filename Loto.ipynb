{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORÁCULO: Primitiva\n",
    "\n",
    "http://www.lotoideas.com/primitiva-resultados-historicos-de-todos-los-sorteos/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "import time\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "def log(*params):\n",
    "    if debug:\n",
    "        for x in params:\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cargar datos\n",
    "datos = pd.read_csv('datos/Primitiva_2013_2018.csv')\n",
    "\n",
    "try:\n",
    "    datos = datos.drop(labels=['comp'], axis=1)\n",
    "except:\n",
    "    None #Ya lo eliminaste en el fichero?\n",
    "\n",
    "log(datos.head(), \"\\n\")\n",
    "    \n",
    "#Poner los datos mas recientes al final...\n",
    "datos = datos.reindex(index=datos.index[::-1])\n",
    "\n",
    "log(datos.head(), \"\\n\")\n",
    "\n",
    "max = datos.max(1).max()\n",
    "min = datos.min(1).min()\n",
    "log(\"MAX: \", max)#49\n",
    "log(\"MIN: \", min)# 1\n",
    "log(\"DIM: \", datos.shape)\n",
    "features = max - min +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Muestra una grafica de la evolucion del error de training y validacion\n",
    "def grafica(hist, offset0 = 0, offset1 = None):\n",
    "    loss = hist.history['loss'][offset0:offset1]\n",
    "    val_loss = hist.history['val_loss'][offset0:offset1]\n",
    "    epochs = range(offset0 + 1, len(loss) + offset0 + 1)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Funciones para mostrar tiempo transcurrido\n",
    "def print_time(time_ini):\n",
    "    sec = round(time.time() - time_ini)\n",
    "    min = 0\n",
    "    if(sec > 60):\n",
    "        min = sec // 60\n",
    "        sec = sec & 60\n",
    "    print(\"TIME: \", min, \"m  \", sec, \"s\")\n",
    "\n",
    "def ini_time():\n",
    "    print(\"Procesando... \", time.ctime())\n",
    "    return time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import winsound\n",
    "def beep():\n",
    "    duration = 500  # millisecond\n",
    "    freq = 900  # Hz\n",
    "    winsound.Beep(freq, duration)\n",
    "    winsound.Beep(freq, duration)\n",
    "    winsound.Beep(freq, 2*duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calcula el error incurrido en la predicción\n",
    "import math\n",
    "\n",
    "##---------------------------------------------------------------------\n",
    "def calc_error_all(pred, real):\n",
    "    error = []\n",
    "    for i in range(len(real)):\n",
    "        error.append(0)\n",
    "        for j in range(len(real[i])):\n",
    "            if(real[i][j] not in pred[i]):\n",
    "                error[i] += 1\n",
    "    for i in range(len(error)):\n",
    "        error[i] = math.floor(error[i]*100.0/6.0)\n",
    "    return error\n",
    "\n",
    "##---------------------------------------------------------------------\n",
    "def calc_error_one(pred, real):\n",
    "    error = 0\n",
    "    for j in range(len(real)):\n",
    "        if(real[j] not in pred):\n",
    "            error += 100.0/6.0\n",
    "    return error\n",
    "\n",
    "##---------------------------------------------------------------------\n",
    "def accuracy_all(model, x, y):\n",
    "    y_pred = translate_all(model.predict(x))\n",
    "    error = calc_error_all(y_pred, devectorize_all(y))\n",
    "    err = 0\n",
    "    for x in error:\n",
    "        err += x\n",
    "    error100 = err/len(error)\n",
    "    acierto100 = 100 - error100\n",
    "    return acierto100\n",
    "\n",
    "def accuracy2_all(model, x, y):\n",
    "    sum_error = 0\n",
    "    for i in range(len(y)):\n",
    "        print(\".\", end=\"\")\n",
    "        pred = model.predict(x[i:(i+1)+seq_len])\n",
    "        pred = translate_one(pred[-1])\n",
    "        real = devectorize_one(y[i])\n",
    "        error  = calc_error_one(pred, real)\n",
    "        sum_error += error\n",
    "    print()\n",
    "    error = sum_error/len(y)\n",
    "    acierto = 100 - error\n",
    "    return acierto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Si el peor de los mejores esta repetido, alguno mejor podria no entrar en la lista\n",
    "def translate_all(pred):\n",
    "    numeros = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        min_mas_alto = sorted(pred[i], key=float, reverse=True)[5]\n",
    "        #print(i, \" min: \", min_mas_alto)\n",
    "        numeros.append([])\n",
    "        for j in range(pred.shape[1]):\n",
    "            if pred[i][j] >= min_mas_alto and len(numeros[i]) < 6:\n",
    "                numeros[i].append(j)\n",
    "        #print(i, \" num: \", numeros[i])\n",
    "    return numeros\n",
    "\n",
    "def translate_one(pred):\n",
    "    numeros = []\n",
    "    min_mas_alto = sorted(pred, key=float, reverse=True)[5]\n",
    "    for j in range(pred.shape[0]):\n",
    "        if pred[j] >= min_mas_alto and len(numeros) < 6:\n",
    "            numeros.append(j)\n",
    "    return numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convierte los numeros enteros premiados en un array binario ONE HOT\n",
    "\n",
    "##\n",
    "def vectorize_all(sequences, dimension=features):\n",
    "    res = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        res[i, sequence-min] = 1\n",
    "    return res\n",
    "\n",
    "##\n",
    "def devectorize_one(valor):\n",
    "    res = []\n",
    "    for i in range(len(valor)):\n",
    "        if(valor[i] > 0):\n",
    "            res.append(i+min)\n",
    "    return res\n",
    "#print(devectorize(np.array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0])), \"\\n\")\n",
    "\n",
    "##\n",
    "def devectorize_all(valores):\n",
    "    i = 0\n",
    "    res = []\n",
    "    for valor in valores:\n",
    "        res.append([])\n",
    "        for j in range(len(valor)):\n",
    "            if(valor[j] > 0):\n",
    "                res[i].append(j+min)\n",
    "        i+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeros = datos.drop(labels=['fecha'], axis=1)\n",
    "\n",
    "log(\"----------------------------------------\\n\")\n",
    "log(numeros.head())\n",
    "log(\"----------------------------------------\\n\")\n",
    "log(np.array(numeros))\n",
    "log(\"----------------------------------------\\n\")\n",
    "\n",
    "num_hot = vectorize_all(np.array(numeros))\n",
    "\n",
    "log(num_hot)\n",
    "log(\"----------\")\n",
    "log(devectorize_one(num_hot[0]))\n",
    "log(devectorize_one(num_hot[1]))\n",
    "log(devectorize_one(num_hot[2]))\n",
    "log(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide los datos en secuencias que el modelo tendrá que aprender\n",
    "seq_len = 100\n",
    "secuencias = []\n",
    "log(len(num_hot), seq_len)\n",
    "for index in range(len(num_hot) - seq_len):\n",
    "    secuencias.append(num_hot[index : index + seq_len])\n",
    "secuencias = np.array(secuencias)\n",
    "###\n",
    "log(devectorize_one(num_hot[0]))\n",
    "log(devectorize_one(secuencias[0][0]))\n",
    "log()\n",
    "log(devectorize_one(num_hot[seq_len-1]))\n",
    "log(devectorize_one(secuencias[0][seq_len-1]))\n",
    "log()\n",
    "log(devectorize_one(num_hot[1]))\n",
    "log(devectorize_one(secuencias[1][0]))\n",
    "log()\n",
    "log(devectorize_one(num_hot[1+seq_len-1]))\n",
    "log(devectorize_one(secuencias[1][seq_len-1]))\n",
    "log()\n",
    "\n",
    "log(devectorize_one(secuencias[0][0]))\n",
    "log(\"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide los datos en Training y Test\n",
    "log(secuencias.shape)\n",
    "\n",
    "row = round(0.9 * secuencias.shape[0])\n",
    "train = secuencias[:int(row), :]\n",
    "\n",
    "log(train.shape)\n",
    "log(devectorize_one(train[0][0]))\n",
    "log(devectorize_one(secuencias[0][0]))\n",
    "\n",
    "#np.random.shuffle(train)\n",
    "\n",
    "x_train = train[:, :-1]#Todos menos el ultimo valor, que es el que hay que predecir\n",
    "log(x_train.shape)\n",
    "log(x_train[0][0])\n",
    "y_train = train[:, -1] #El ultimo valor, que es el que interesa predecir\n",
    "log(y_train.shape)\n",
    "\n",
    "x_test = secuencias[int(row):, :-1]\n",
    "log(x_test.shape)\n",
    "y_test = secuencias[int(row):, -1]\n",
    "log(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "log(x_train.shape,  seq_len)\n",
    "\n",
    "log()\n",
    "log(devectorize_one(num_hot[0]))\n",
    "log(devectorize_one(x_train[0][0]))\n",
    "log()\n",
    "log(devectorize_one(num_hot[seq_len-2]))\n",
    "log(devectorize_one(x_train[0][seq_len-2]))\n",
    "log()\n",
    "log(devectorize_one(num_hot[seq_len-1]))\n",
    "log(devectorize_one(y_train[0]))\n",
    "log()\n",
    "log(devectorize_one(num_hot[x_train.shape[0]+seq_len-2]))\n",
    "log(devectorize_one(x_test[0][seq_len-2]))\n",
    "log()\n",
    "log(devectorize_one(num_hot[x_train.shape[0]+seq_len-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo minimo: 3 numeros de 6 => 50% !!!\n",
    "\n",
    "model1 ->\n",
    "\n",
    "4 capas LSTM, 1 densa, epoca=, batch=128, m0s/0e -> \n",
    "\n",
    "5 capas LSTM, 1 densa, epoca=150, batch=128, 4m20s/0e -> OK TRAIN = 12.94 / OK TEST = 14.98\n",
    "5 capas LSTM, 1 densa, epoca=160, batch=128, 7m52s/0e -> OK TRAIN = 12.33 / OK TEST = 15.02\n",
    "\n",
    "epoca > 160 -> peor\n",
    "epoca < 150 -> peor\n",
    "\n",
    "6 capas LSTM, 1 densa, epoca=150, batch=128, 5m52s/150e -> OK TRAIN = 12.90 / OK TEST = 11.07   (0.10842311382293701)\n",
    "\n",
    "                       epoca=101                                      11.89             13.02\n",
    "\n",
    "\n",
    "model2 ->\n",
    "\n",
    "1 capa LSTM, 1 bidireccional, epoca=250, batch=128, 5m16s/250e -> OK TRAIN = 11.67 / OK TEST = 12.23\n",
    "\n",
    "\n",
    "2 capas LSTM -> OK TEST = 13.565891472868188\n",
    "2 y 3 capas bidireccionales -> OK TEST = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Crea la RNN\n",
    "#features = x_train.shape[2]\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=True))\n",
    "    #model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=True))\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=True))\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=True))\n",
    "\n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=False))\n",
    "    #model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Dense(units=features, activation='sigmoid'))\n",
    "    #model.add(layers.Dense(units=features))\n",
    "    #model.add(layers.Activation(\"linear\"))\n",
    "\n",
    "    #start = time.time()\n",
    "    #model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    #print(\"> Compilation Time : \", round(time.time() - start), \" segundos\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando...  Fri Feb  2 15:50:16 2018\n"
     ]
    }
   ],
   "source": [
    "#Entrenar la RNN\n",
    "batch_size=128\n",
    "epochs = 165\n",
    "model = build_model()\n",
    "timeini = ini_time()\n",
    "hist1 = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=0)\n",
    "print_time(timeini)\n",
    "beep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Val.Loss: \", hist1.history['val_loss'][epochs-1])\n",
    "grafica(hist1)\n",
    "grafica(hist1, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Error\n",
    "acierto100a = accuracy_all(model, x_train, y_train)\n",
    "print(\"M1 ACIERTO TRAIN: %.2f -------------------------------\" % acierto100a)\n",
    "acierto100a = accuracy_all(model, x_test, y_test)\n",
    "print(\"M1 ACIERTO TEST:  %.2f -------------------------------\" % acierto100a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(acierto100a > 15):\n",
    "    model.save(\"bumodels/lotoA_\"+str(acierto100a)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train again with the better epoch\n",
    "timeini = ini_time()\n",
    "best_epoch = 140\n",
    "model2 = build_model()\n",
    "hist2 = model2.fit(x_train, y_train, batch_size=batch_size, epochs=best_epoch, validation_split=0.05, verbose=0)\n",
    "print_time(timeini)\n",
    "beep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Val.Loss: \", hist2.history['val_loss'][best_epoch])\n",
    "grafica(hist2, 10,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Error\n",
    "acierto100b = accuracy_all(model2, x_train, y_train)\n",
    "print(\"M2 ACIERTO TRAIN: %.2f -------------------------------\" % acierto100b)\n",
    "acierto100b = accuracy_all(model2, x_test, y_test)\n",
    "print(\"M2 ACIERTO TEST:  %.2f -------------------------------\" % acierto100b)\n",
    "\n",
    "#print(\"ACIERTO TRAIN: %.2f -------------------------------\" % accuracy2_all(model2, x_train, y_train))\n",
    "#print(\"ACIERTO TEST:  %.2f -------------------------------\" % accuracy2_all(model2, x_test, y_test))\n",
    "\n",
    "numeros_ganadores = translate_all(model2.predict(x_test))\n",
    "log(\"REAL: \", devectorize_one(y_test[0]), \" vs PRED: \", numeros_ganadores[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(acierto100b > 15):\n",
    "    model2.save(\"bumodels/lotoB_\"+str(acierto100b)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Modificar porcentage TRAIN / TEST a ver como responde..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430, 100, 49)\n",
      "(100, 100, 49)\n",
      "[11, 29, 36, 42, 45, 48]  vs real  [3, 6, 25, 31, 32, 40]\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[11, 29, 36, 42, 45, 48]\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Predecir\n",
    "log(secuencias.shape)\n",
    "log(secuencias[-seq_len-1:-1].shape)\n",
    "numeros_ganadores = model.predict(secuencias[-seq_len:-1])\n",
    "numeros_ganadores = translate_one(numeros_ganadores[-1])\n",
    "print(numeros_ganadores, \" vs real \", devectorize_one(secuencias[-1][-1]))\n",
    "print()\n",
    "\n",
    "numeros_ganadores = model.predict(secuencias[-seq_len:])\n",
    "numeros_ganadores = translate_one(numeros_ganadores[-1])\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(numeros_ganadores)\n",
    "print(\"----------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"X:\\n========\")\n",
    "print(x_train.shape)\n",
    "print()\n",
    "n = 0\n",
    "for i in x_train:\n",
    "    m = 0\n",
    "    if(n < 2 or n > x_train.shape[0]-2):\n",
    "        for j in i:\n",
    "            if(m < 2 or m > i.shape[0]-2):\n",
    "                print(n, m, devectorize_one(j))\n",
    "            elif(m==10):\n",
    "                print(\"...\")\n",
    "            m += 1\n",
    "        print(\"-----------------------------------\")\n",
    "    elif(n==10):\n",
    "        print(\"[...]\\n\")\n",
    "    n += 1\n",
    "\n",
    "    \n",
    "print(\"\\nY:\\n========\")\n",
    "print(y_train.shape)\n",
    "print()\n",
    "n = 0\n",
    "for i in y_train:\n",
    "    if(n < 2 or n > y_train.shape[0]-2):\n",
    "        print(n,devectorize_one(i))\n",
    "    elif(n==10):\n",
    "        print(\"...\")\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log(devectorize_one(x_train[1][-1]), \" corresponde con \", devectorize_one(y_train[0]))\n",
    "log(devectorize_one(x_train[2][-1]), \" corresponde con \", devectorize_one(y_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RNN LSTM Bidireccional\n",
    "def build_model2():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.LSTM(\n",
    "        input_shape=(None, features),\n",
    "        units=features,\n",
    "        return_sequences=True))\n",
    "    \n",
    "    #model.add(layers.Embedding(features, 32))\n",
    "    model.add(layers.Bidirectional(layers.LSTM(input_shape=(None, features), units=features, return_sequences=True)))\n",
    "    model.add(layers.Bidirectional(layers.LSTM(input_shape=(None, features), units=features, return_sequences=False)))\n",
    "    \n",
    "    model.add(layers.Dense(features, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando...  Fri Feb  2 15:02:14 2018\n",
      "TIME:  7 m   36 s\n"
     ]
    }
   ],
   "source": [
    "#Entrenar la RNN\n",
    "batch_size=128\n",
    "epochs = 150\n",
    "model3 = build_model2()\n",
    "timeini = ini_time()\n",
    "hist3 = model3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=0)\n",
    "print_time(timeini)\n",
    "beep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Val.Loss: \", hist3.history['val_loss'][epochs-1])\n",
    "grafica(hist3)\n",
    "grafica(hist3, 10, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Error\n",
    "acierto100c = accuracy_all(model2, x_train, y_train)\n",
    "print(\"M3 ACIERTO TRAIN: %.2f -------------------------------\" % acierto100c)\n",
    "acierto100c = accuracy_all(model2, x_test, y_test)\n",
    "print(\"M3 ACIERTO TEST:  %.2f -------------------------------\" % acierto100c)\n",
    "print()\n",
    "#print(\"ACIERTO TRAIN: %.2f -------------------------------\" % accuracy2_all(model3, x_train, y_train))\n",
    "#print(\"ACIERTO TEST:  %.2f -------------------------------\" % accuracy2_all(model3, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(acierto100c > 15):\n",
    "    model3.save(\"bumodels/lotoC_\"+str(acierto100c)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
